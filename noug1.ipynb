{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "837ea2c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81387c09",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda\\lib\\site-packages\\scipy\\__init__.py:155: UserWarning: A NumPy version >=1.18.5 and <1.25.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "from ollama import chat\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06e1eb38",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\arupnanda\\AppData\\Roaming\\Python\\Python39\\site-packages\\torch\\_utils.py:776: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    }
   ],
   "source": [
    "model = SentenceTransformer('all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "71ce3d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data():\n",
    "    with open ('c:\\\\projects\\\\llama\\\\mydata.py', 'r') as file:\n",
    "        mydata = file.readlines()\n",
    "        return (mydata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "56794bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_relevant_data(query, k=2):\n",
    "    query_vec = model.encode(query)\n",
    "    res_matrix = []\n",
    "    for data_vec in data_vectors:\n",
    "        s = np.dot(data_vec, query_vec) / (np.linalg.norm(data_vec) * np.linalg.norm(query_vec)) \n",
    "        res_matrix.append(s)\n",
    "    top_k = np.argsort(res_matrix)[-k:]\n",
    "    r = [mydata[i] for i in top_k]\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "56accd8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ollama_query(question, context):\n",
    "    formatted_prompt = f\"Question: {question}\\n\\nContext: {context}\"\n",
    "    response = chat(model='llama3.2', \n",
    "                    messages=[{'role': 'user', 'content': formatted_prompt}],\n",
    "                    options={\"temperature\":0.1}\n",
    "                   )\n",
    "    r = response['message']['content']\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a7cdd169",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag_chain(question):\n",
    "    relevant_context = \"\\n\\n\".join(find_relevant_data(question))\n",
    "    return ollama_query(question, relevant_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3cbccb72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.15964119, 0.3140605, 0.45015368, 0.13024138, 0.1787784, 0.21059735, 0.3786223, 0.15005347]\n",
      "As Sam Altman walked into the conference room, he was immediately struck by the eclectic mix of attire that surrounded him. Amidst the sea of button-down shirts and tailored trousers, one person stood out - Larry, the co-founder of OpenAI, who was sporting a faded band t-shirt and ripped jeans. The contrast between their styles was jarring, yet somehow fitting for two individuals who had spent years pushing the boundaries of artificial intelligence together. With a confident stride, Sam extended his hand to Larry, ready to shake hands and begin their collaboration that would change the face of AI forever.\n"
     ]
    }
   ],
   "source": [
    "mydata = read_data()\n",
    "data_vectors = model.encode(mydata)\n",
    "answer = rag_chain(\"Write an introduction for Sam when he meets Larry for the first time\")\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f66614",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
