{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bbb55d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ollama import chat\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "003c5c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer('all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b63e86cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_relevant_docs(query, k=2):\n",
    "    query_vec = model.encode(query)\n",
    "    res_matrix = []\n",
    "    for data_vec in data_vectors:\n",
    "        s = np.dot(data_vec, query_vec) / (np.linalg.norm(data_vec) * np.linalg.norm(query_vec)) \n",
    "        res_matrix.append(s)\n",
    "    # print(res_matrix)\n",
    "    top_k = np.argsort(res_matrix)[-k:]\n",
    "    print(top_k)\n",
    "    r = [mydata[i] for i in top_k]\n",
    "    # print(r)\n",
    "    return r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b8d1b4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ollama_llm(question, context):\n",
    "    formatted_prompt = f\"Question: {question}\\n\\nContext: {context}\"\n",
    "    response = chat(model='llama3.2', messages=[{'role': 'user', 'content': formatted_prompt}],\n",
    "                    options={\"temperature\":1}\n",
    "                    )\n",
    "    r = response['message']['content']\n",
    "    # print(r)\n",
    "    return r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b5bc84c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag_chain(question):\n",
    "    relevant_context = \"\\n\\n\".join(find_relevant_docs(question, 10))\n",
    "    return ollama_llm(question, relevant_context)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7baa2f9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\"Oracle is a large corporation\"\\n', '\"Larry Ellison was one of the founders of Oracle\"\\n', '\"Larry seldom wears a suit\"\\n', '\"ORCL is the stock symbol of Oracle\"\\n', '\"ORCL is a pioneer in AI infrastructure\"\\n', '\"Oracle and OpenAI are close partners in AI space\"\\n', '\"Sam Altman is the CEO of OpenAI\"\\n', '\"OpenIA is a leader in AI software\"']\n"
     ]
    }
   ],
   "source": [
    "mydata = []\n",
    "with open ('c:\\\\projects\\\\llama\\\\mydata.py', 'r') as file:\n",
    "    mydata = file.readlines()\n",
    "\n",
    "type( mydata)\n",
    "print(mydata)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "311fe732",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_vectors = model.encode(mydata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4db83fb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 4 7 0 5 6 1 2]\n"
     ]
    }
   ],
   "source": [
    "# answer = rag_chain(\"Does Larry Like Sam?\")\n",
    "answer = rag_chain(\"What happened wjhen Sam met Larry?\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "02b960c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is not enough information to determine what happened when Sam met Larry. However, we can make some educated guesses based on the context.\n",
      "\n",
      "Given that Larry Ellison is one of the founders of Oracle and Sam Altman is the CEO of OpenAI, which is a close partner with Oracle in the AI space, it's possible that Sam Altman (OpenAI) may have met Larry Ellison (Oracle) at an event or meeting related to their partnership.\n",
      "\n",
      "Additionally, knowing that Larry Ellison is known for his casual style (he seldom wears a suit), we can make some humorous guesses about their meeting. Perhaps Sam Altman was dressed in a more formal attire when they met, and Larry Ellison showed up in his signature relaxed style, causing them to crack each other up or having an amusing conversation about business attire.\n",
      "\n",
      "However, without more specific information, it's difficult to determine what actually happened during their meeting.\n"
     ]
    }
   ],
   "source": [
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e35c8c9c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
